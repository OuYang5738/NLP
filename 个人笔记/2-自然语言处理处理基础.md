@[TOC](文章目录)
---

# 前言#
	自然语言处理的基础问题：文本如何在计算机内表示，才能达到易于处理和计算的目的。
	词的表示大体经过：独热表示、分布式表示、词向量表示。
	三大类自然语言处理任务：语言模型、基础任务、应用任务。
	基础任务包括：中文分词、词性标注、句法分析、语义分析。
	应用任务包括信息抽取、情感分析、问答系统、机器翻译、对话系统。
	任务基础包括文本分类、结构预测、序列到序列。
---

`提示：以下是本篇文章正文内容`

# 一、文本表示 #

## 1.1词的独热表示 ##
词的独热表示，即使用一个词表大小的向量表示一个词，然后将词表中的第i个词wi表示为向量。
在该向量中，词中第i个词在第i维上被设置为1，其他维均为0。
缺点：独热模型会导致数据稀疏问题。
为了缓解数据稀疏问题，可以提取更多和词相关的泛化特征：词性特征、词义特征（WordNet）、词类聚特征。

## 1.2词的分布式表示 ##
### 1.2.1分布式语义假设 ###
分布式语义假设：词的含义可由其上下文的分布进行表示。
以词所在句子中的其他词语作为上下文，创建词语共现频次表。
存在问题：1.高频词误导计算结果 2.共现频次无法反映词之间的高阶关系（无法传递关系）。3.仍然存在稀疏性问题（向量中还存在着大量的值为0）。

### 1.2.2点互信息 ###
主要针对分布式语义假设出现的问题（高频词误导计算结果）。
直接想法：如果一个词与很多词共现，则降低其权重；反之如果一个词只与个别词共现，则提高其权重。分别是共现概率、w和c单独出现的概率
![PMI.gif](https://img-blog.csdnimg.cn/img_convert/7bdec882bf1039b8ca62776b36cd3d79.gif)


通过PMI计算可知：如果共现概率较高、单独出现的概率也较高，则PMI值会变小；反之PMI值会变大。可以较好的解决高频词误导计算结果的问题。
当共现频率出现次数较低时，PMI可能会出现负值。
所以需要PMII(w,c)=max(PMII(w,c),0)
### 1.2.3奇异值分解 ###
解决共现频次无法反映词之间的高阶关系。
对共现矩阵进行奇异值分解：
![SVD.gif](https://s2.loli.net/2022/03/27/blSx2DkmUTaHpYP.gif)
## 1.3词嵌入式 ##
分布式表示一旦完成训练，则无法修改。
词嵌入表示也使用一个连续、低维、稠密的向量来表示词，称为词向量。
与分布式表示的区别在于：其赋值方式不同。
词向量中的向量值是随着目标任务的优化过程而自动调整的。
具体步骤：先利用自然语言文本中所蕴含的自监督信号（即上下文的共现信息），预训练词向量
## 1.4文本的词袋表示 ##
词袋表示，就是假设文本中的词语是没有顺讯的集合，将文本中的全部词所对应的向量表示相加（可以是独热，分布式或者是独热+分布式）。
优点：简单、直观
缺点：
1.没有考虑词的顺序信息，导致顺序不同，结果一样
2.无法融入上下文信息
解决方法：增加词表（治标不治本，词表增大会导致数据稀疏性）

# 二、自然语言处理任务 #
	三大类常见自然语言处理任务：语言模型、基础任务、应用任务
## 2.1语言模型 ##
语言模型(LM)也叫统计语言模型，是描述自然语言概率分布的模型。
统计语言模型是一个单词序列上的概率分布，对于一个给定长度为m的序列，它可以为整个序列产生一个概率 P(w_1,w_2,…,w_m) 。其实就是想办法找到一个概率分布，它可以表示任意一个句子或序列出现的概率。



---

# 总结
